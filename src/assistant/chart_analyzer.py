# src/assistant/chart_analyzer.py

"""
ChartAnalyzer - Ph√¢n t√≠ch bi·ªÉu ƒë·ªì b·∫±ng GPT-4 v·ªõi h·ªá th·ªëng cache.
T√≠ch h·ª£p v√†o dashboard Streamlit ƒë·ªÉ cung c·∫•p ph√¢n t√≠ch AI cho m·ªói bi·ªÉu ƒë·ªì.
"""

import json
import hashlib
import os
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Optional, Any

# Load .env file for API key
from dotenv import load_dotenv
load_dotenv()

from .prompts import get_prompt, get_system_prompt


class ChartAnalyzer:
    """
    Ph√¢n t√≠ch bi·ªÉu ƒë·ªì cryptocurrency b·∫±ng GPT-4o-mini.
    
    Features:
    - Prompt templates ri√™ng cho t·ª´ng lo·∫°i bi·ªÉu ƒë·ªì
    - Cache k·∫øt qu·∫£ ƒë·ªÉ ti·∫øt ki·ªám API calls
    - T√≠ch h·ª£p d·ªÖ d√†ng v·ªõi Streamlit
    
    Example:
        analyzer = ChartAnalyzer()
        result = analyzer.analyze_chart(
            coin="bitcoin",
            chart_type="rolling_volatility",
            chart_data={"vol_14d_latest": 3.5, ...},
            chart_title="Bi·∫øn ƒê·ªông LƒÉn"
        )
        st.markdown(result)
    """
    
    def __init__(
        self, 
        api_key: Optional[str] = None,
        cache_enabled: bool = True,
        cache_duration_hours: int = 24,
        cache_dir: str = "data/cache/chart_analysis",
        model: str = "gpt-4o-mini"
    ):
        """
        Kh·ªüi t·∫°o ChartAnalyzer.
        
        Args:
            api_key: OpenAI API key. N·∫øu None, l·∫•y t·ª´ OPENAI_API_KEY env var.
            cache_enabled: B·∫≠t/t·∫Øt cache.
            cache_duration_hours: Th·ªùi gian cache h·∫øt h·∫°n (gi·ªù).
            cache_dir: Th∆∞ m·ª•c l∆∞u cache.
            model: T√™n model OpenAI (gpt-4o-mini, gpt-4o, gpt-4-turbo, etc.)
        """
        # API key
        if api_key is None:
            api_key = os.getenv("OPENAI_API_KEY")
        self.api_key = api_key
        
        # Cache settings
        self.cache_enabled = cache_enabled
        self.cache_duration = timedelta(hours=cache_duration_hours)
        self.cache_dir = Path(cache_dir)
        
        # Model
        self.model = model
        
        # OpenAI client
        self.client = None
        self._init_openai()
        
        # Ensure cache directory exists
        if self.cache_enabled:
            self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    def _init_openai(self):
        """Initialize OpenAI client."""
        if self.api_key:
            try:
                from openai import OpenAI
                self.client = OpenAI(api_key=self.api_key)
            except ImportError:
                print("‚ö†Ô∏è openai package not installed. Run: pip install openai")
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to initialize OpenAI: {e}")
    
    def _generate_cache_key(
        self, 
        coin: str, 
        chart_type: str, 
        chart_data: Dict
    ) -> str:
        """
        T·∫°o cache key d·ª±a tr√™n coin, chart_type v√† data hash.
        
        Returns:
            Cache key string: {coin}_{chart_type}_{data_hash}_{date}
        """
        # Hash chart_data ƒë·ªÉ t·∫°o unique key
        data_str = json.dumps(chart_data, sort_keys=True, default=str)
        data_hash = hashlib.md5(data_str.encode()).hexdigest()[:8]
        
        # Include current date ƒë·ªÉ cache h·∫øt h·∫°n khi ng√†y m·ªõi
        date_str = datetime.now().strftime("%Y-%m-%d")
        
        return f"{coin}_{chart_type}_{data_hash}_{date_str}"
    
    def _get_cache_path(self, cache_key: str) -> Path:
        """Get path to cache file."""
        return self.cache_dir / f"{cache_key}.json"
    
    def _get_cached(
        self, 
        coin: str, 
        chart_type: str, 
        chart_data: Dict
    ) -> Optional[str]:
        """
        L·∫•y k·∫øt qu·∫£ t·ª´ cache n·∫øu c√≤n h·∫°n.
        
        Returns:
            Cached analysis string ho·∫∑c None n·∫øu kh√¥ng c√≥/h·∫øt h·∫°n.
        """
        if not self.cache_enabled:
            return None
        
        cache_key = self._generate_cache_key(coin, chart_type, chart_data)
        cache_path = self._get_cache_path(cache_key)
        
        if not cache_path.exists():
            return None
        
        try:
            with open(cache_path, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # Check expiration
            cached_time = datetime.fromisoformat(cache_data['timestamp'])
            if datetime.now() - cached_time > self.cache_duration:
                # Cache expired
                cache_path.unlink()  # Delete expired cache
                return None
            
            return cache_data['analysis']
            
        except Exception:
            return None
    
    def _save_cache(
        self, 
        coin: str, 
        chart_type: str, 
        chart_data: Dict,
        analysis: str
    ) -> None:
        """L∆∞u k·∫øt qu·∫£ ph√¢n t√≠ch v√†o cache."""
        if not self.cache_enabled:
            return
        
        cache_key = self._generate_cache_key(coin, chart_type, chart_data)
        cache_path = self._get_cache_path(cache_key)
        
        cache_data = {
            'coin': coin,
            'chart_type': chart_type,
            'timestamp': datetime.now().isoformat(),
            'analysis': analysis
        }
        
        try:
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to save cache: {e}")
    
    def _build_prompt(
        self, 
        chart_type: str, 
        coin: str,
        chart_data: Dict,
        chart_title: str
    ) -> str:
        """
        X√¢y d·ª±ng prompt ho√†n ch·ªânh t·ª´ template v√† data.
        
        Args:
            chart_type: Lo·∫°i bi·ªÉu ƒë·ªì
            coin: T√™n coin
            chart_data: D·ªØ li·ªáu t·ª´ bi·ªÉu ƒë·ªì
            chart_title: Ti√™u ƒë·ªÅ bi·ªÉu ƒë·ªì
            
        Returns:
            Prompt string ƒë√£ ƒëi·ªÅn data
        """
        template = get_prompt(chart_type)
        
        if not template:
            return f"""## PH√ÇN T√çCH BI·ªÇU ƒê·ªí

**Coin:** {coin}
**Ti√™u ƒë·ªÅ:** {chart_title}

### D·ªÆ LI·ªÜU:
{json.dumps(chart_data, ensure_ascii=False, indent=2)}

### Y√äU C·∫¶U:
H√£y ph√¢n t√≠ch bi·ªÉu ƒë·ªì n√†y v√† ƒë∆∞a ra nh·∫≠n x√©t chi ti·∫øt v·ªÅ √Ω nghƒ©a c·ªßa d·ªØ li·ªáu.
"""
        
        # Prepare data for formatting
        format_data = {
            'coin': coin,
            'chart_title': chart_title,
            **chart_data
        }
        
        try:
            return template.format(**format_data)
        except KeyError as e:
            # Handle missing keys gracefully
            return template + f"\n\n**D·ªØ li·ªáu b·ªï sung:** {json.dumps(chart_data, ensure_ascii=False)}"
    
    def _call_openai(self, prompt: str) -> str:
        """
        G·ªçi OpenAI API ƒë·ªÉ ph√¢n t√≠ch.
        
        Args:
            prompt: User prompt
            
        Returns:
            Ph√¢n t√≠ch t·ª´ GPT
        """
        if not self.client:
            return self._get_fallback_analysis(prompt)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": get_system_prompt()},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            error_str = str(e)
            if "insufficient_quota" in error_str.lower():
                return f"‚ùå **H·∫øt quota API:** Vui l√≤ng n·∫°p th√™m credit t·∫°i [platform.openai.com/account/billing](https://platform.openai.com/account/billing)\n\n*Chi ti·∫øt: {error_str}*"
            return f"‚ùå **L·ªói khi g·ªçi API:** {error_str}\n\nVui l√≤ng ki·ªÉm tra API key v√† k·∫øt n·ªëi m·∫°ng."
    
    def _get_fallback_analysis(self, prompt: str) -> str:
        """
        Fallback khi kh√¥ng c√≥ API key - tr·∫£ v·ªÅ h∆∞·ªõng d·∫´n.
        """
        return """‚ö†Ô∏è **Ch∆∞a c·∫•u h√¨nh API Key**

ƒê·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng ph√¢n t√≠ch AI, vui l√≤ng:

1. **L·∫•y API key t·ª´ OpenAI:**
   - Truy c·∫≠p [platform.openai.com](https://platform.openai.com)
   - T·∫°o API key m·ªõi

2. **Th√™m v√†o file `.env`:**
   ```
   OPENAI_API_KEY=sk-proj-xxxxx
   ```

3. **Kh·ªüi ƒë·ªông l·∫°i dashboard**

---

üí° *Model gpt-4o-mini r·∫•t r·∫ª: ~$0.15/1M tokens input*
"""
    
    def analyze_chart(
        self,
        coin: str,
        chart_type: str,
        chart_data: Dict[str, Any],
        chart_title: str,
        force_refresh: bool = False
    ) -> str:
        """
        Ph√¢n t√≠ch m·ªôt bi·ªÉu ƒë·ªì c·ª• th·ªÉ.
        
        Args:
            coin: T√™n coin (v√≠ d·ª•: "bitcoin", "ethereum")
            chart_type: Lo·∫°i bi·ªÉu ƒë·ªì (t·ª´ prompts.CHART_PROMPTS keys)
            chart_data: Dictionary ch·ª©a d·ªØ li·ªáu t·ª´ bi·ªÉu ƒë·ªì
            chart_title: Ti√™u ƒë·ªÅ hi·ªÉn th·ªã c·ªßa bi·ªÉu ƒë·ªì
            force_refresh: B·ªè qua cache v√† g·ªçi API m·ªõi
            
        Returns:
            Ph√¢n t√≠ch chi ti·∫øt d∆∞·ªõi d·∫°ng markdown string
        """
        coin = coin.lower()
        
        # Step 1: Check cache
        if not force_refresh:
            cached = self._get_cached(coin, chart_type, chart_data)
            if cached:
                return cached + "\n\n---\n*üì¶ T·ª´ cache - Click ƒë·ªÉ l√†m m·ªõi*"
        
        # Step 2: Build prompt
        prompt = self._build_prompt(chart_type, coin, chart_data, chart_title)
        
        # Step 3: Call OpenAI
        analysis = self._call_openai(prompt)
        
        # Step 4: Save to cache
        if "‚ùå" not in analysis and "‚ö†Ô∏è **Ch∆∞a c·∫•u h√¨nh" not in analysis:
            self._save_cache(coin, chart_type, chart_data, analysis)
        
        return analysis
    
    def clear_cache(self, coin: Optional[str] = None) -> int:
        """
        X√≥a cache.
        
        Args:
            coin: N·∫øu ch·ªâ ƒë·ªãnh, ch·ªâ x√≥a cache c·ªßa coin ƒë√≥. 
                  N·∫øu None, x√≥a to√†n b·ªô cache.
                  
        Returns:
            S·ªë file cache ƒë√£ x√≥a
        """
        if not self.cache_dir.exists():
            return 0
        
        count = 0
        for cache_file in self.cache_dir.glob("*.json"):
            if coin is None or cache_file.name.startswith(coin):
                cache_file.unlink()
                count += 1
        
        return count
    
    def get_cache_stats(self) -> Dict:
        """
        L·∫•y th·ªëng k√™ cache.
        
        Returns:
            Dictionary v·ªõi th√¥ng tin cache
        """
        if not self.cache_dir.exists():
            return {"total_files": 0, "total_size_kb": 0}
        
        files = list(self.cache_dir.glob("*.json"))
        total_size = sum(f.stat().st_size for f in files)
        
        return {
            "total_files": len(files),
            "total_size_kb": round(total_size / 1024, 2),
            "cache_dir": str(self.cache_dir)
        }


# Singleton instance for easy import
_analyzer_instance: Optional[ChartAnalyzer] = None


def get_chart_analyzer() -> ChartAnalyzer:
    """
    L·∫•y singleton instance c·ªßa ChartAnalyzer.
    Ti·ªán l·ª£i ƒë·ªÉ s·ª≠ d·ª•ng trong Streamlit m√† kh√¥ng c·∫ßn kh·ªüi t·∫°o nhi·ªÅu l·∫ßn.
    
    Returns:
        ChartAnalyzer instance
        
    Example:
        from src.assistant.chart_analyzer import get_chart_analyzer
        
        analyzer = get_chart_analyzer()
        result = analyzer.analyze_chart(...)
    """
    global _analyzer_instance
    
    if _analyzer_instance is None:
        _analyzer_instance = ChartAnalyzer()
    
    return _analyzer_instance
